---
title: "Demystifying the Relationship Between Fixed/Random Effects and Unmeasured Confounding in Panel Data Analysis"
author: "Yicheng Shen, Yanjiao Yang, Huiyin Lin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
    - \setlength{\parskip}{0em}
    - \setlength{\parindent}{2em}
    - \usepackage{indentfirst}
    - \usepackage{float}
    - \usepackage{setspace}\onehalfspacing
output: 
  pdf_document: 
    extra_dependencies: ["float"]
    number_sections: true
bibliography: SYL.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = F, warning = F, message = F)
library(tidyverse)
library(lme4)
library(ggplot2)
library(gridExtra)
library(kableExtra)
library(GGally)
ggplot2::theme_set(ggplot2::theme_bw())
knitr::opts_chunk$set(fig.align = 'center')
knitr::opts_chunk$set(fig.pos = "H")

load("bias_result_full.RData")
bias_result_full$confound_treatment = factor(bias_result_full$confound_treatment)
levels(bias_result_full$confound_treatment)[levels(bias_result_full$confound_treatment)=="Uniform"] <- "Very Strong"
```


\section{Introduction}

Panel data analysis is a widely used statistical tool in econometrics to study the relationships between variables over time. However, this type of analysis is susceptible to confounding variables, which can bias the estimated coefficients and distort the interpretation of the results. 
Fixed and random effects models frequently emerge in panel data analysis to account for confounding variables that are time-invariant [@gunasekara2014fixed] or time-varying [@li2011nonpara; @ahn2013panel]. 
A common belief among econometricians is that fixed effects (FE) or random effects (RE) models can absorb unmeasured confounding variables [@angrist2009mostly], but the mechanism behind this claim is mysterious and not well-understood. 
In this research paper, we aim to explore the relationship between fixed/random effects and time-invariant unmeasured confounding in panel data analysis and provide insights into whether and in what sense these models can address this issue.

Our simulation suggests that fixed/random effects can remedy the issue of unmeasured confounding to a certain extent, but there are still systematic bias resulting from the relationship between unmeasured confounding and the treatment assignment. **[more stuff here]**




\section{Background}

In typical observational studies, failing to capture significant unmeasured confounding gives rise to biased estimates of treatment effects, which compels practitioners to develop methods of assessing and handling uncontrolled confounding [@vanderweele2011unmeasured]. 
The question of whether fixed/random effects models can account for unmeasured confounding in panel data analysis has been the subject of much debate particuarly in the econometrics literature. 
A number of studies have explored this issue from different angles and with varying degrees of empirical evidence.

One line of research has focused on theoretical arguments for why fixed/random effects models might be effective at absorbing unmeasured confounding. 
For example, @angrist2009mostly discuss the strategies that use data with a time or cohort dimension to control for unobserved-but-fixed omitted variables.
@hausman1981panel argue that fixed effects models can control for the time-invariant confounders by essentially differencing them out, while random effects models can account for time-varying confounders that are uncorrelated with the fixed effects. More recently, @wooldridge2010econometric has suggested that fixed effects models can be viewed as a form of quasi-experimental design that mimics a randomized controlled trial, and thus can address the unobserved component to the extent that such designs do.

Other scholars have challenged the notion that fixed/random effects models can fully absorbing unmeasured confounding. For example, @mundlak1978pooling once argued that random effects models are biased when unobserved heterogeneity is correlated with observed variables, and that fixed effects models are limited by the fact that they cannot estimate time-invariant covariates. 
@hazlett2022understanding point out that random effect estimates in multilevel models are equivalent to fixed effects estimates that have been shrunken through a regularization process. When the source of unmeasured confounding is at the group-level, the FE approach could unbiasedly estimates treatment effects, but with poor estimates of standard errors. Bias emerges in random effects models because their variables are not “allowed” to adjust for confounding as intended and thus fails to remove the unmeasured confounding.
Furthermore, @bell2015explaining note that while fixed effects models can provide reasonable estimates of treatment effects, they may still suffer from omitted variable bias if the unobserved confounding variable is correlated with the time-varying variables.

Therefore, the effectiveness of fixed/random effects models in accounting for unmeasured confounding and obtaining unbiased estimates of treatment effects in panel data analysis remains a topic of ongoing research and debate.
As such, our projects seeks to explore the trends of potential bias when applying fixed/random effects models in the face of unmeasured confounding.



\section{Method}

We presume that specifying an intercept for every individual in the study is an appropriate method to address unmeasured confounding, $A$. 

```{r, echo=F, out.width="50%"}
knitr::include_graphics("Image/DAG.png")
```


\subsection{Continuous Case}

Our data generation process (DGP) uses the following model specifications:
$$
\begin{aligned}
E\left(\mathrm{Y}_{i t} \mid A_i, \mathrm{X}_{i t}, t, \mathrm{D}_{i t}\right)& =\alpha+\lambda_t+\rho \mathrm{D}_{i t}+ \gamma A_i+ \delta \mathrm{X}_{i t} \\
Y_{it} &= \alpha+\lambda_t+\rho \mathrm{D}_{i t}+ \gamma A_i+ \delta \mathrm{X}_{i t}+ \epsilon_{it} \\
\end{aligned}
$$


In our DGP of artificial panel data, there are 100 individuals and 10 time points. Covariate, $X$, for each individualis simulated from $N(0,1)$. The unmeasured counfounding, $A$, is either from $N(0,1)$ or $\text{Uniform(0,1)}$. 

The coefficient for covariate, $\gamma$, is chosen arbitrarily as 5. 



**Difference-in-difference (DID) estimator**



$$
\tau^{DID} = (\bar Y_{1, t+1} - \bar Y_{1, t}) - (\bar Y_{0, t+1} - \bar Y_{0, t})
$$




**Regression model**

$$
\begin{aligned}
Y_{it} &= \alpha+\lambda_t+\rho \mathrm{D}_{i t}+ \delta \mathrm{X}_{i t}+ \epsilon_{it} 
\end{aligned}
$$




**Fixed effects model**

$$
\begin{aligned}
\alpha_i &\equiv \alpha+ \gamma A_i\\
Y_{it} &= \alpha_i+\lambda_t+\rho \mathrm{D}_{i t}+ \delta \mathrm{X}_{i t}+ \epsilon_{it} 
\end{aligned}
$$




**Random effects model**

Our random effects model is essentially a random intercept model. 

We use `lmer` from the `lme4` package to fit the random intercept model. 

$$
\begin{aligned}
\alpha_i &\equiv \alpha+ \gamma A_i\\
Y_{it} &= \alpha_i+\lambda_t+\rho \mathrm{D}_{i t}+ \delta \mathrm{X}_{i t}+ \epsilon_{it} \\
& \text{where } \alpha_i \sim N(\mu_i, \sigma^2)
\end{aligned}
$$



\subsection{Binary Case}

fit `glm`

RE: `glmer` from the `lme4`


\section{Result}

In Figure \ref{fig:bias_with_ols}, we show that 

```{r With OLS, fig.cap="\\label{fig:bias_with_ols} Average bias of estimated treatment effects from four types of estimation methods.",fig.height=6, fig.width=11}
gridExtra::grid.arrange(
bias_result_full %>% pivot_longer(cols = c("DID_bias","OLS_bias","FE_bias", "RE_bias"), names_to = "Bias_Type", values_to = "Bias") %>%
  filter(rho == 5) %>%
  ggplot(aes(x = gamma, y = Bias, color = Bias_Type)) + geom_point() + geom_line() + facet_wrap(~confound_treatment) + labs(x = expression(gamma))
,
bias_result_full %>% pivot_longer(cols = c("DID_bias","OLS_bias","FE_bias", "RE_bias"), names_to = "Bias_Type", values_to = "Bias") %>%
  filter(gamma == 5) %>%
  ggplot(aes(x = rho, y = Bias, color = Bias_Type)) + geom_point() + geom_line() + facet_wrap(~confound_treatment) + labs(x = expression(rho))
)
```


In Figure \ref{fig:bias_without_ols}, we show that 

```{r Without OLS, fig.cap="\\label{fig:bias_without_ols} Compareing average bias of estimated treatment effects from DID, FE, and RE models.",fig.height=6, fig.width=11}
gridExtra::grid.arrange(
bias_result_full %>% pivot_longer(cols = c("DID_bias","OLS_bias","FE_bias", "RE_bias"), names_to = "Bias_Type", values_to = "Bias") %>%
  filter(Bias_Type != "OLS_bias", rho == 5) %>% 
  ggplot(aes(x = gamma, y = Bias, color = Bias_Type)) + geom_point() + geom_line() + facet_wrap(~confound_treatment) + labs(x = expression(gamma))
,
bias_result_full %>% pivot_longer(cols = c("DID_bias","OLS_bias","FE_bias", "RE_bias"), names_to = "Bias_Type", values_to = "Bias") %>%
  filter(Bias_Type != "OLS_bias", gamma == 5) %>%
  ggplot(aes(x = rho, y = Bias, color = Bias_Type)) + geom_point() + geom_line()  + facet_wrap(~confound_treatment) + labs(x = expression(rho))
)
```



\section{Discussion}


Limitation and further direction: 

Time-variant confounding? 

More time points?

Estimated coefficients of latent variable?


Overall, the literature suggests that while fixed/random effects models may be useful in controlling for unmeasured confounding in panel data analysis, they are not a panacea. Other methods, such as instrumental variables or regression discontinuity designs, may be more necessary in certain cases to fully address this issue.



<!-- \newpage -->

\section{Reference}

